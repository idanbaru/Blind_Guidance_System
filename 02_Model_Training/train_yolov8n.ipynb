{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2faa1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch DirectML: True\n",
      "GPU name: Intel(R) Arc(TM) Graphics\u0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import torch_directml\n",
    "import shutil\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Torch DirectML:\", torch_directml.is_available())\n",
    "print(\"GPU name:\", torch_directml.device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aeeff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'annotated_outdoor_yolo'\n",
    "output_dir = 'dataset_yolo'\n",
    "\n",
    "os.makedirs(os.path.join(output_dir), exist_ok=True)\n",
    "\n",
    "images_dir = os.path.join(input_dir, 'images')\n",
    "labels_dir = os.path.join(input_dir, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d16497ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 217 - 69.77%\n",
      "Validation set size: 31 - 9.97%\n",
      "Test set size: 63 - 20.26%\n",
      "\n",
      "Dataset split saved to dataset_yolo\\dataset_split.json\n"
     ]
    }
   ],
   "source": [
    "# Get the list of image files (assuming all formats are .jpg, change if needed)\n",
    "image_files = sorted([f for f in os.listdir(images_dir) if f.endswith(\".jpg\")])\n",
    "\n",
    "# Create dataset indices\n",
    "dataset_size = len(image_files)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "# Split into train (70%), val (10%), test (20%)\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = train_test_split(train_indices, test_size=0.125, random_state=42)\n",
    "\n",
    "# Store indices in a dictionary\n",
    "split_data = {\n",
    "    \"train\": train_indices,\n",
    "    \"val\": val_indices,\n",
    "    \"test\": test_indices\n",
    "}\n",
    "\n",
    "print(f\"Train set size: {len(train_indices)} - {len(train_indices)/len(indices)*100:.2f}%\")\n",
    "print(f\"Validation set size: {len(val_indices)} - {len(val_indices)/len(indices)*100:.2f}%\")\n",
    "print(f\"Test set size: {len(test_indices)} - {len(test_indices)/len(indices)*100:.2f}%\\n\")\n",
    "\n",
    "# Save the split indices as JSON\n",
    "json_split_path = os.path.join(output_dir, \"dataset_split.json\")\n",
    "with open(json_split_path, \"w\") as f:\n",
    "    json.dump(split_data, f, indent=4)\n",
    "\n",
    "print(f\"Dataset split saved to {json_split_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Copy complete! Summary:\n",
      "\n",
      "Split 'train': 284 images, 284 labels.\n",
      "Split 'val': 59 images, 59 labels.\n",
      "Split 'test': 115 images, 115 labels.\n"
     ]
    }
   ],
   "source": [
    "# List and sort both image and label files\n",
    "image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
    "label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "\n",
    "# Sanity check\n",
    "assert len(image_files) == len(label_files), \"Image and label counts do not match!\"\n",
    "\n",
    "# Define dataset splits\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Create output directories\n",
    "for split in splits:\n",
    "    for category in [\"images\", \"labels\"]:\n",
    "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "# Loop over your splits\n",
    "for split, indices in split_data.items():\n",
    "    for idx in indices:\n",
    "        image_name = image_files[idx]\n",
    "        label_name = label_files[idx]\n",
    "\n",
    "        image_src = os.path.join(images_dir, image_name)\n",
    "        label_src = os.path.join(labels_dir, label_name)\n",
    "\n",
    "        image_dest = os.path.join(output_dir, split, \"images\", image_name)\n",
    "        label_dest = os.path.join(output_dir, split, \"labels\", label_name)\n",
    "\n",
    "        shutil.copy(image_src, image_dest)\n",
    "        shutil.copy(label_src, label_dest)\n",
    "\n",
    "# Print final counts for verification\n",
    "print(\"\\n✅ Copy complete! Summary:\\n\")\n",
    "for split in split_data.keys():\n",
    "    image_folder = os.path.join(output_dir, split, \"images\")\n",
    "    label_folder = os.path.join(output_dir, split, \"labels\")\n",
    "\n",
    "    num_images = len([f for f in os.listdir(image_folder) if f.endswith('.jpg')]) if os.path.exists(image_folder) else 0\n",
    "    num_labels = len([f for f in os.listdir(label_folder) if f.endswith('.txt')]) if os.path.exists(label_folder) else 0\n",
    "\n",
    "    print(f\"Split '{split}': {num_images} images, {num_labels} labels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-no-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
