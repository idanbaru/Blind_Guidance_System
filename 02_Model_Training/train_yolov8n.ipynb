{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import torch_directml\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Torch DirectML:\", torch_directml.is_available())\n",
    "print(\"GPU name:\", torch_directml.device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeeff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'annotated_outdoor_yolo'\n",
    "output_dir = 'dataset_yolo'\n",
    "\n",
    "os.makedirs(os.path.join(output_dir), exist_ok=True)\n",
    "\n",
    "images_dir = os.path.join(input_dir, 'images')\n",
    "labels_dir = os.path.join(input_dir, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da723d38",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16497ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of image files (assuming all formats are .jpg, change if needed)\n",
    "image_files = sorted([f for f in os.listdir(images_dir) if f.endswith(\".jpg\")])\n",
    "\n",
    "# Create dataset indices\n",
    "dataset_size = len(image_files)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "# Split into train (70%), val (10%), test (20%)\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=199742069)\n",
    "train_indices, val_indices = train_test_split(train_indices, test_size=0.125, random_state=199742069)\n",
    "\n",
    "# Store indices in a dictionary\n",
    "split_data = {\n",
    "    \"train\": train_indices,\n",
    "    \"val\": val_indices,\n",
    "    \"test\": test_indices\n",
    "}\n",
    "\n",
    "print(f\"Train set size: {len(train_indices)} - {len(train_indices)/len(indices)*100:.2f}%\")\n",
    "print(f\"Validation set size: {len(val_indices)} - {len(val_indices)/len(indices)*100:.2f}%\")\n",
    "print(f\"Test set size: {len(test_indices)} - {len(test_indices)/len(indices)*100:.2f}%\\n\")\n",
    "\n",
    "# Save the split indices as JSON\n",
    "json_split_path = os.path.join(output_dir, \"dataset_split.json\")\n",
    "with open(json_split_path, \"w\") as f:\n",
    "    json.dump(split_data, f, indent=4)\n",
    "\n",
    "print(f\"Dataset split saved to {json_split_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and sort both image and label files\n",
    "image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
    "label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "\n",
    "# Sanity check\n",
    "assert len(image_files) == len(label_files), \"Image and label counts do not match!\"\n",
    "\n",
    "# Define dataset splits\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Create output directories\n",
    "for split in splits:\n",
    "    for category in [\"images\", \"labels\"]:\n",
    "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "# Loop over your splits\n",
    "for split, indices in split_data.items():\n",
    "    for idx in indices:\n",
    "        image_name = image_files[idx]\n",
    "        label_name = label_files[idx]\n",
    "\n",
    "        image_src = os.path.join(images_dir, image_name)\n",
    "        label_src = os.path.join(labels_dir, label_name)\n",
    "\n",
    "        image_dest = os.path.join(output_dir, split, \"images\", image_name)\n",
    "        label_dest = os.path.join(output_dir, split, \"labels\", label_name)\n",
    "\n",
    "        shutil.copy(image_src, image_dest)\n",
    "        shutil.copy(label_src, label_dest)\n",
    "\n",
    "# Print final counts for verification\n",
    "print(\"\\nCopy complete! Summary:\\n\")\n",
    "for split in split_data.keys():\n",
    "    image_folder = os.path.join(output_dir, split, \"images\")\n",
    "    label_folder = os.path.join(output_dir, split, \"labels\")\n",
    "\n",
    "    num_images = len([f for f in os.listdir(image_folder) if f.endswith('.jpg')]) if os.path.exists(image_folder) else 0\n",
    "    num_labels = len([f for f in os.listdir(label_folder) if f.endswith('.txt')]) if os.path.exists(label_folder) else 0\n",
    "\n",
    "    print(f\"Split '{split}': {num_images} images, {num_labels} labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a .yaml file for the YOLO trainer configuration\n",
    "dataset_yaml_path = os.path.join(output_dir, 'dataset.yaml')\n",
    "classes_path = os.path.join(input_dir, 'classes.txt')\n",
    "\n",
    "with open(classes_path, 'r') as f:\n",
    "    names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(names)\n",
    "\n",
    "# Construct .yaml file to include dataset paths\n",
    "data_yaml = {\n",
    "    \"names\": names,\n",
    "    \"nc\": len(names),\n",
    "    \"train\": os.path.abspath(os.path.join(output_dir, \"train\", \"images\")),\n",
    "    \"val\": os.path.abspath(os.path.join(output_dir, \"val\", \"images\")),\n",
    "    \"test\": os.path.abspath(os.path.join(output_dir, \"test\", \"images\"))\n",
    "}\n",
    "\n",
    "# Save to .yaml file\n",
    "with open(dataset_yaml_path, \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(f\"YAML file saved at {dataset_yaml_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e593d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e43cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device as GPU, here using intel ARC so need torch_directml instead of torch (which has CUDA only for Nvidia's GPUs)\n",
    "import torch_directml\n",
    "\n",
    "# Create DirectML device\n",
    "dml_device = torch_directml.device()\n",
    "\n",
    "# Set device globally in YOLO before training (so it doesn't try to select CUDA)\n",
    "model.to(dml_device)  # <-- manually move your model to DirectML device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for training the YOLO model\n",
    "yolo_params = {\n",
    "    'image_size' : 640,\n",
    "    'batch_size' : 16,\n",
    "    'epochs' : 100\n",
    "}\n",
    "\n",
    "dataset_yaml_path = os.path.join(output_dir, 'dataset.yaml')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "            data=dataset_yaml_path,\n",
    "            imgsz=yolo_params['image_size'],\n",
    "            epochs=yolo_params['epochs'],\n",
    "            batch=yolo_params['batch_size'],\n",
    "            name=f'yolov8n_outdoor_train',\n",
    "            project=os.path.join(output_dir, 'runs'),\n",
    "            device=0,\n",
    "            patience=0 \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661e788",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e601e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = os.path.join(output_dir,'runs','yolov8n_outdoor_train','weights','best.pt')\n",
    "best_model = YOLO(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = best_model.val(data=dataset_yaml_path, split='test', name=f'test')\n",
    "print(f\"mAP@50 test results: {test_results.box.map50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d45e63e",
   "metadata": {},
   "source": [
    "## Export as ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export trained model to .onnx to later convert to .blob using BlobConverter\n",
    "model.export(format='onnx', dynamic=True, simplify=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-no-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
